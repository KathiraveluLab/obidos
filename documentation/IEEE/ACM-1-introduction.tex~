\section{Introduction}

\label{ch:lorem}

Cloud simulations are used in evaluating architectures, algorithms, topologies, and strategies that are under research and development, tackling many issues such as resource management, application scheduling, load balancing, workload execution, and optimizing energy consumption. While the exact environment of the cloud platform may not be accessible to the developers at the early stages of development, simulations give an overall idea on the related parameters, resource requirements, performance, and output. With the increasing complexity of the systems that are simulated, cloud simulations are getting larger, and the larger simulations tend to take longer and longer to complete being run in a single node. Also, cloud simulation environments require a considerable amount of memory and processing power to simulate a complex cloud scenario. Processors are increasingly becoming more powerful with multi-core architectures and the computing clusters in the research laboratories themselves could be used to run complicated large simulations in a distributed manner. However, current simulation tools provide very limited support to utilize these resources, as they are mostly written with a sequential execution model targeting to run on a single server.

Java In-memory data grids provide a distributed execution and storage model for problems in the grid-scale. They offer scalability and seamless integration with persistent storage. Hazelcast~\cite{hazelcast}, Infinispan~\cite{infinispan}, and Terracotta BigMemory\footnote{http://terracotta.org/products/bigmemory} are some of the currently most used platforms for distributed execution and storage~\cite{ferrante2003java}. Using these platforms, users could create data grids and distributed caches on utility computers, to execute much larger jobs that could not run on any single computer, or that would take a huge time to execute with slow response. Functionality and scalability of the cloud simulators could thus be extended using in-memory data grids solutions.
%
Existing cloud simulators also lack the ability to simulate MapReduce tasks, while there are simulators just specific to MapReduce. However, a MapReduce simulator could be implemented along with the cloud simulator, to simulate complex scenarios involving MapReduce tasks and cloud applications, such as load balancing the MapReduce tasks into different datacenters and power-aware resource scheduling. Cloud and MapReduce simulations can be executed on top of in-memory data grids, that execute over the computer clusters.

Public resource sharing or cycle sharing models allow acquiring resources for computing and storage from the volunteers for the tasks that are heavy in such requirements. This volunteer computing paradigm enables distributed execution of embarrassingly parallel jobs on the private computers of geographically distributed volunteers. Specific CPU and memory intensive research areas have utilized the volunteer computing model, where millions of volunteers offer their computer resources, while they are idle. BOINC (Berkeley Open Infrastructure for Network Computing) is a software that enables scientists to operate on public resource sharing model~\cite{anderson2004boinc}. It is a server, client, and statistics system, that is later used by SETI@home and other projects~\cite{beberg2009folding}. SETI (Search for Extraterrestrial Intelligence)~\cite{anderson2002seti}, Folding@home~\cite{shirts2006screen,beberg2009folding}, and Gnome@home~\cite{larson2002folding}, tackle problems of different domains, with geographically distributed computing resources provided by the volunteers. Condor is a scheduling system that maximizes the utilization of the workstations. Under-utilized or idling workstations offer their computing resources to the workstations that are overloaded. This resource sharing increases the overall productivity of the research labs or the cluster of workstations~\cite{litzkow1988condor}.

Exploiting the existing simulation approaches that are heavily centralized, and the distributed execution platforms, cloud simulations can be made distributed, such that they would be able to utilize the computer clusters in the research labs. Distributed simulations could enable larger simulations to execute in a shorter time with a better response, whilst making it possible to simulate scenarios that may not even be possible on a single instance. Utilizing distributed computers to share the cycles to the simulation, as required by the simulation, would enable simulating larger and more complex scenarios that could not be simulated effectively in a single node, or it could be a very time consuming execution. While cycle sharing and volunteer computing is used in scientific research and grid computing projects, the cycle sharing model is not utilized to provide computing resources for cloud simulations. Moreover, when the resource providers are inside a trusted private network such as a research lab, security concerns related to cycle sharing could be considered lightly. Hence, the cycle sharing model can be leveraged to operate in a private cluster to provide a scalable middleware platform.

This paper describes first $Cloud^{2}Sim$, an adaptively scaling middleware platform for concurrent and distributed cloud simulator, by leveraging CloudSim~\cite{cloudsim,cloudgridsim} as the core module, whilst taking advantage of the distributed shared memory provided by Hazelcast and in-memory key-value data grid of Infinispan. The Hazelcast based distributed simulator is implemented along with prototype deployments and samples. Infinispan is integrated into CloudSim, such that it can be used to implement the middleware platform to scale the simulator. Second, we describe two distributed implementations of a MapReduce simulator, leveraging centralized Hazelcast and Infinispan MapReduce implementations as core modules. Cycle sharing of the instances in the cluster, inspired by volunteer computing, is used as the model to achieve a scalable, adaptive, and elastic middleware platform for all the simulations. Hazelcast and Infinispan are integrated into core CloudSim as a compatibility layer for a seamless integration and invocation of cloud simulations. The whole simulation platform is implemented as a scalable middleware platform for cloud and MapReduce simulations, but it can be extended for other applications as well.
Therefore, being elastic and adaptive, and thus cloud-ready, $Cloud^{2}Sim$ can be the basis of a concurrent and distributed Simulation-as-a-Service for Cloud and MapReduce simulations.

In the upcoming sections, we will further analyze the proposed adaptively scaling middleware platform for the simulations in a distributed and concurrent manner. Section 2 will address background information on cloud and MapReduce simulators, and distributed execution frameworks. Section 3 discusses the solution architecture of $Cloud^{2}Sim$, the proposed middleware platform, and how CloudSim is enhanced and extended as to become a distributed and concurrent cloud simulator. Section 4 deals with the implementation details of $Cloud^{2}Sim$. $Cloud^{2}Sim$ was benchmarked against CloudSim and was evaluated on multiple nodes, with results discussed in Section 5. Finally, Section 6 closes the paper discussing the research current state and future enhancements.



